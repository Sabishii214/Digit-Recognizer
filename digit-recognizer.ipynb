{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2ae8418",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-01-06T04:43:43.435443Z",
     "iopub.status.busy": "2026-01-06T04:43:43.435154Z",
     "iopub.status.idle": "2026-01-06T04:43:45.359944Z",
     "shell.execute_reply": "2026-01-06T04:43:45.358511Z"
    },
    "papermill": {
     "duration": 1.931879,
     "end_time": "2026-01-06T04:43:45.361689",
     "exception": false,
     "start_time": "2026-01-06T04:43:43.429810",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/digit-recognizer/sample_submission.csv\n",
      "/kaggle/input/digit-recognizer/train.csv\n",
      "/kaggle/input/digit-recognizer/test.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e64b88f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T04:43:45.370142Z",
     "iopub.status.busy": "2026-01-06T04:43:45.369710Z",
     "iopub.status.idle": "2026-01-06T04:43:57.026660Z",
     "shell.execute_reply": "2026-01-06T04:43:57.025898Z"
    },
    "papermill": {
     "duration": 11.663038,
     "end_time": "2026-01-06T04:43:57.028318",
     "exception": false,
     "start_time": "2026-01-06T04:43:45.365280",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da8e203b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T04:43:57.036595Z",
     "iopub.status.busy": "2026-01-06T04:43:57.036211Z",
     "iopub.status.idle": "2026-01-06T04:43:57.043246Z",
     "shell.execute_reply": "2026-01-06T04:43:57.042310Z"
    },
    "papermill": {
     "duration": 0.012854,
     "end_time": "2026-01-06T04:43:57.044693",
     "exception": false,
     "start_time": "2026-01-06T04:43:57.031839",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80257842",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T04:43:57.053676Z",
     "iopub.status.busy": "2026-01-06T04:43:57.052846Z",
     "iopub.status.idle": "2026-01-06T04:43:57.057823Z",
     "shell.execute_reply": "2026-01-06T04:43:57.056820Z"
    },
    "papermill": {
     "duration": 0.010903,
     "end_time": "2026-01-06T04:43:57.059292",
     "exception": false,
     "start_time": "2026-01-06T04:43:57.048389",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40516faa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T04:43:57.068084Z",
     "iopub.status.busy": "2026-01-06T04:43:57.067616Z",
     "iopub.status.idle": "2026-01-06T04:43:57.073993Z",
     "shell.execute_reply": "2026-01-06T04:43:57.073094Z"
    },
    "papermill": {
     "duration": 0.012383,
     "end_time": "2026-01-06T04:43:57.075311",
     "exception": false,
     "start_time": "2026-01-06T04:43:57.062928",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/digit-recognizer/sample_submission.csv\n",
      "/kaggle/input/digit-recognizer/train.csv\n",
      "/kaggle/input/digit-recognizer/test.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29873942",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T04:43:57.083472Z",
     "iopub.status.busy": "2026-01-06T04:43:57.083175Z",
     "iopub.status.idle": "2026-01-06T04:43:57.090294Z",
     "shell.execute_reply": "2026-01-06T04:43:57.089412Z"
    },
    "papermill": {
     "duration": 0.013053,
     "end_time": "2026-01-06T04:43:57.091781",
     "exception": false,
     "start_time": "2026-01-06T04:43:57.078728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomMNISTDataset(Dataset):\n",
    "  def __init__(self, csv_file, transform=None, is_test=False):\n",
    "    self.data = pd.read_csv(csv_file)\n",
    "    self.transform = transform\n",
    "    self.is_test = is_test\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    item = self.data.iloc[idx]\n",
    "\n",
    "    if self.is_test:\n",
    "      image = item.values.reshape(28, 28).astype(np.uint8)\n",
    "      label = None\n",
    "    else:\n",
    "      image = item[1:].values.reshape(28, 28).astype(np.uint8)\n",
    "      label = item.iloc[0]\n",
    "\n",
    "    image = transforms.ToPILImage()(image)\n",
    "\n",
    "    if self.transform is not None:\n",
    "      image = self.transform(image)\n",
    "\n",
    "    if self.is_test:\n",
    "      return image\n",
    "    else:\n",
    "      return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43dc3669",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T04:43:57.100005Z",
     "iopub.status.busy": "2026-01-06T04:43:57.099680Z",
     "iopub.status.idle": "2026-01-06T04:43:57.104400Z",
     "shell.execute_reply": "2026-01-06T04:43:57.103461Z"
    },
    "papermill": {
     "duration": 0.010427,
     "end_time": "2026-01-06T04:43:57.105757",
     "exception": false,
     "start_time": "2026-01-06T04:43:57.095330",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55de8dcd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T04:43:57.113762Z",
     "iopub.status.busy": "2026-01-06T04:43:57.113475Z",
     "iopub.status.idle": "2026-01-06T04:43:57.118538Z",
     "shell.execute_reply": "2026-01-06T04:43:57.117699Z"
    },
    "papermill": {
     "duration": 0.01061,
     "end_time": "2026-01-06T04:43:57.119784",
     "exception": false,
     "start_time": "2026-01-06T04:43:57.109174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sample_submission.csv', 'train.csv', 'test.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Path to the folder containing the dataset files\n",
    "path = \"/kaggle/input/digit-recognizer\"\n",
    "\n",
    "# List all files in that folder\n",
    "files = os.listdir(path)\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "935fc0b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T04:43:57.128983Z",
     "iopub.status.busy": "2026-01-06T04:43:57.127963Z",
     "iopub.status.idle": "2026-01-06T04:44:01.388233Z",
     "shell.execute_reply": "2026-01-06T04:44:01.387437Z"
    },
    "papermill": {
     "duration": 4.266197,
     "end_time": "2026-01-06T04:44:01.389691",
     "exception": false,
     "start_time": "2026-01-06T04:43:57.123494",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = CustomMNISTDataset(csv_file=os.path.join(path, 'train.csv'), transform=transform, is_test=False)\n",
    "test_dataset = CustomMNISTDataset(csv_file=os.path.join(path, 'test.csv'), transform=transform, is_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c2125d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T04:44:01.399102Z",
     "iopub.status.busy": "2026-01-06T04:44:01.398516Z",
     "iopub.status.idle": "2026-01-06T04:44:01.403446Z",
     "shell.execute_reply": "2026-01-06T04:44:01.402421Z"
    },
    "papermill": {
     "duration": 0.011227,
     "end_time": "2026-01-06T04:44:01.404797",
     "exception": false,
     "start_time": "2026-01-06T04:44:01.393570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Size: 42000, Test Size: 28000\n"
     ]
    }
   ],
   "source": [
    "print('Train Size: ' + str(len(train_dataset)) +', Test Size: ' + str(len(test_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1388a5a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T04:44:01.413545Z",
     "iopub.status.busy": "2026-01-06T04:44:01.413260Z",
     "iopub.status.idle": "2026-01-06T04:44:01.454386Z",
     "shell.execute_reply": "2026-01-06T04:44:01.453372Z"
    },
    "papermill": {
     "duration": 0.047318,
     "end_time": "2026-01-06T04:44:01.455978",
     "exception": false,
     "start_time": "2026-01-06T04:44:01.408660",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -0.8588, -0.7647,  0.0745,  0.0745,  0.5059,\n",
       "           -0.3255, -0.4353, -0.9922, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000,  0.9608,  0.9922,  0.9922,  0.9922,  0.9922,\n",
       "            0.7020,  0.9294,  0.1843, -0.7490, -0.5765, -0.8824, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -0.8980, -0.3255,  0.9922,  0.9922,  0.9922,  0.9922,  0.9922,\n",
       "            0.9922,  0.9922,  0.9922,  0.8118,  0.9922, -0.1843, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.8745,\n",
       "            0.4039,  0.9922,  0.9922,  0.9922,  0.9922,  0.9922,  0.9922,\n",
       "            0.9922,  0.9922,  0.9922,  0.9922,  0.9922,  0.9059, -0.3333,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.4353,\n",
       "            0.9922,  0.9922,  0.9922,  0.9922,  0.9922, -0.1451, -0.3490,\n",
       "            0.5608,  0.9922,  0.9922,  0.9922,  0.9922,  0.9922,  0.3412,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.5216,  0.4980,\n",
       "            0.9922,  0.9922,  0.9922,  0.1529,  0.1529, -0.6471, -1.0000,\n",
       "           -0.9137, -0.7725,  0.5686,  0.9922,  0.9922,  0.9922,  0.9922,\n",
       "            0.6627, -0.4039, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.3490,\n",
       "            0.9922,  0.9922,  0.9922, -0.4745, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000,  0.0039, -0.3490,  0.9922,  0.9922,\n",
       "            0.9922,  0.2000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9922,  0.3647,\n",
       "            0.9922,  0.9922, -0.3020, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -0.8039,  0.8824,  0.9922,\n",
       "            0.9922,  0.2000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.6314,  0.9922,\n",
       "            0.9922,  0.9922, -0.7725, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.3020,  0.9922,\n",
       "            0.9922,  0.7569, -0.9059, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.3725,  0.9922,\n",
       "            0.9922,  0.8824, -0.8118, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.4118,  0.9922,\n",
       "            0.9922,  0.9922, -0.8667, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.4980,  0.9922,\n",
       "            0.9922,  0.4588, -0.9451, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.6235,  0.9922,\n",
       "            0.9922,  0.9922, -0.8667, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -0.8902,  0.8196,  0.9922,\n",
       "            0.9922,  0.9922, -0.7725, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.6235,  0.9922,\n",
       "            0.9922,  0.9922, -0.8667, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -0.8588,  0.9922,  0.9922,\n",
       "            0.9922,  0.9922, -0.7725, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -0.8745,  0.6392,  0.9922,\n",
       "            0.9922,  0.1765, -0.9922, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -0.9843,  0.2784,  0.9922,\n",
       "            0.9922,  0.9922, -0.7725, -0.9059, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000,  0.2627,  0.9922,  0.9922,\n",
       "            0.9216, -0.7569, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.2627,  0.9922,\n",
       "            0.9922,  0.9922,  0.9922,  0.9922,  0.5843, -0.4824, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000,  0.6392,  0.9922,  0.9922,\n",
       "            0.9922,  0.3412, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.8824,\n",
       "            0.6157,  0.9922,  0.9922,  0.9922,  0.9922,  0.5216, -0.6235,\n",
       "           -0.6235, -0.7333, -0.6784, -0.6235,  0.9922,  0.9922,  0.9922,\n",
       "            0.9922, -0.3255, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -0.5294,  0.6627,  0.9922,  0.9922,  0.9922,  0.9922,  0.9922,\n",
       "            0.9922,  0.8275,  0.9059,  0.9922,  0.9922,  0.9922,  0.8745,\n",
       "           -0.3255, -0.9137, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -0.3255,  0.9059,  0.9922,  0.9922,  0.9922,  0.9922,\n",
       "            0.9922,  0.9922,  0.9922,  0.9922,  0.9922,  0.9059, -0.4510,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -0.1059,  0.4275,  0.9922,  0.9922,  0.9922,\n",
       "            0.9922,  0.9922,  0.9922,  0.9922,  0.9922, -0.8824, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -0.8980, -0.9373, -0.4039,  0.1451,  0.9922,\n",
       "            1.0000,  0.9922,  1.0000,  0.1451, -0.8510, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000]]]),\n",
       " 0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df206b7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T04:44:01.465113Z",
     "iopub.status.busy": "2026-01-06T04:44:01.464772Z",
     "iopub.status.idle": "2026-01-06T04:44:01.470153Z",
     "shell.execute_reply": "2026-01-06T04:44:01.469220Z"
    },
    "papermill": {
     "duration": 0.012019,
     "end_time": "2026-01-06T04:44:01.471950",
     "exception": false,
     "start_time": "2026-01-06T04:44:01.459931",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_loader =torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "test_loader =torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d5963a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T04:44:01.481176Z",
     "iopub.status.busy": "2026-01-06T04:44:01.480550Z",
     "iopub.status.idle": "2026-01-06T04:44:01.969423Z",
     "shell.execute_reply": "2026-01-06T04:44:01.968340Z"
    },
    "papermill": {
     "duration": 0.495292,
     "end_time": "2026-01-06T04:44:01.971146",
     "exception": false,
     "start_time": "2026-01-06T04:44:01.475854",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Size: torch.Size([64, 1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for example_data, example_labels in train_loader:\n",
    "  example_image = example_data[0]\n",
    "  print(\"Input Size:\", example_data.size())\n",
    "\n",
    "  example_image_numpy = example_image.permute(1, 2, 0).numpy()\n",
    "\n",
    "  plt.imshow(example_image_numpy)\n",
    "  plt.title(f'Label: {example_labels[0]}')\n",
    "  plt.show()\n",
    "\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f06d240",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T04:44:01.980925Z",
     "iopub.status.busy": "2026-01-06T04:44:01.980557Z",
     "iopub.status.idle": "2026-01-06T04:44:01.988476Z",
     "shell.execute_reply": "2026-01-06T04:44:01.987523Z"
    },
    "papermill": {
     "duration": 0.015784,
     "end_time": "2026-01-06T04:44:01.991028",
     "exception": false,
     "start_time": "2026-01-06T04:44:01.975244",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # Flattened size after conv + pool: 128*7*7\n",
    "        self.fc1 = nn.Linear(128 * 7 * 7, 128)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, 10)  # 10 classes for MNIST\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)  # flatten except batch dimension\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39980f91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T04:44:02.000721Z",
     "iopub.status.busy": "2026-01-06T04:44:02.000410Z",
     "iopub.status.idle": "2026-01-06T04:44:02.016397Z",
     "shell.execute_reply": "2026-01-06T04:44:02.015473Z"
    },
    "papermill": {
     "duration": 0.023066,
     "end_time": "2026-01-06T04:44:02.018138",
     "exception": false,
     "start_time": "2026-01-06T04:44:01.995072",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = SimpleCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5301dbcb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T04:44:02.027488Z",
     "iopub.status.busy": "2026-01-06T04:44:02.027200Z",
     "iopub.status.idle": "2026-01-06T06:33:39.638848Z",
     "shell.execute_reply": "2026-01-06T06:33:39.637813Z"
    },
    "papermill": {
     "duration": 6577.646508,
     "end_time": "2026-01-06T06:33:39.668792",
     "exception": false,
     "start_time": "2026-01-06T04:44:02.022284",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch: 100, Loss: 2.2944100165367125\n",
      "Epoch: 1, Batch: 200, Loss: 2.2681589984893797\n",
      "Epoch: 1, Batch: 300, Loss: 2.1847637057304383\n",
      "Epoch: 1, Batch: 400, Loss: 1.822020585536957\n",
      "Epoch: 1, Batch: 500, Loss: 1.0970177394151688\n",
      "Epoch: 1, Batch: 600, Loss: 0.7493681144714356\n",
      "Epoch: 2, Batch: 100, Loss: 0.9320390084385872\n",
      "Epoch: 2, Batch: 200, Loss: 0.48779209166765214\n",
      "Epoch: 2, Batch: 300, Loss: 0.4609822969138622\n",
      "Epoch: 2, Batch: 400, Loss: 0.42536938324570656\n",
      "Epoch: 2, Batch: 500, Loss: 0.4014312508702278\n",
      "Epoch: 2, Batch: 600, Loss: 0.3738798129558563\n",
      "Epoch: 3, Batch: 100, Loss: 0.5362146762013436\n",
      "Epoch: 3, Batch: 200, Loss: 0.3069046160578728\n",
      "Epoch: 3, Batch: 300, Loss: 0.2972524520754814\n",
      "Epoch: 3, Batch: 400, Loss: 0.28235703632235526\n",
      "Epoch: 3, Batch: 500, Loss: 0.24787671700119973\n",
      "Epoch: 3, Batch: 600, Loss: 0.2643126406520605\n",
      "Epoch: 4, Batch: 100, Loss: 0.38802549421787264\n",
      "Epoch: 4, Batch: 200, Loss: 0.23269206292927266\n",
      "Epoch: 4, Batch: 300, Loss: 0.22017111539840697\n",
      "Epoch: 4, Batch: 400, Loss: 0.21182530179619788\n",
      "Epoch: 4, Batch: 500, Loss: 0.20189740583300592\n",
      "Epoch: 4, Batch: 600, Loss: 0.20478120997548102\n",
      "Epoch: 5, Batch: 100, Loss: 0.29234392158687117\n",
      "Epoch: 5, Batch: 200, Loss: 0.17754722829908132\n",
      "Epoch: 5, Batch: 300, Loss: 0.17928249422460796\n",
      "Epoch: 5, Batch: 400, Loss: 0.17061133354902266\n",
      "Epoch: 5, Batch: 500, Loss: 0.16084400095045567\n",
      "Epoch: 5, Batch: 600, Loss: 0.16375913921743632\n",
      "Epoch: 6, Batch: 100, Loss: 0.250185922421515\n",
      "Epoch: 6, Batch: 200, Loss: 0.14359166204929352\n",
      "Epoch: 6, Batch: 300, Loss: 0.15855571556836368\n",
      "Epoch: 6, Batch: 400, Loss: 0.15020198367536067\n",
      "Epoch: 6, Batch: 500, Loss: 0.14845873214304448\n",
      "Epoch: 6, Batch: 600, Loss: 0.14900696588680148\n",
      "Epoch: 7, Batch: 100, Loss: 0.21805534431710838\n",
      "Epoch: 7, Batch: 200, Loss: 0.12992070876061917\n",
      "Epoch: 7, Batch: 300, Loss: 0.13154275458306075\n",
      "Epoch: 7, Batch: 400, Loss: 0.12955843806266784\n",
      "Epoch: 7, Batch: 500, Loss: 0.12807181680575014\n",
      "Epoch: 7, Batch: 600, Loss: 0.14465465903282165\n",
      "Epoch: 8, Batch: 100, Loss: 0.20436480298638343\n",
      "Epoch: 8, Batch: 200, Loss: 0.12784210775047541\n",
      "Epoch: 8, Batch: 300, Loss: 0.11859823066741228\n",
      "Epoch: 8, Batch: 400, Loss: 0.12193185713142157\n",
      "Epoch: 8, Batch: 500, Loss: 0.12184952745214105\n",
      "Epoch: 8, Batch: 600, Loss: 0.12051758890971541\n",
      "Epoch: 9, Batch: 100, Loss: 0.19637331917881964\n",
      "Epoch: 9, Batch: 200, Loss: 0.12079178496263922\n",
      "Epoch: 9, Batch: 300, Loss: 0.1224812250956893\n",
      "Epoch: 9, Batch: 400, Loss: 0.1037492735311389\n",
      "Epoch: 9, Batch: 500, Loss: 0.12297707142308355\n",
      "Epoch: 9, Batch: 600, Loss: 0.1018502077460289\n",
      "Epoch: 10, Batch: 100, Loss: 0.17571763593703507\n",
      "Epoch: 10, Batch: 200, Loss: 0.10948752509430051\n",
      "Epoch: 10, Batch: 300, Loss: 0.09769117325544358\n",
      "Epoch: 10, Batch: 400, Loss: 0.10422888251021505\n",
      "Epoch: 10, Batch: 500, Loss: 0.10774821348488331\n",
      "Epoch: 10, Batch: 600, Loss: 0.11161399960517883\n",
      "Epoch: 11, Batch: 100, Loss: 0.16214231284335257\n",
      "Epoch: 11, Batch: 200, Loss: 0.10214457191526889\n",
      "Epoch: 11, Batch: 300, Loss: 0.10035518420860172\n",
      "Epoch: 11, Batch: 400, Loss: 0.10908852144144475\n",
      "Epoch: 11, Batch: 500, Loss: 0.09348882745951415\n",
      "Epoch: 11, Batch: 600, Loss: 0.0952055380307138\n",
      "Epoch: 12, Batch: 100, Loss: 0.15724410227499902\n",
      "Epoch: 12, Batch: 200, Loss: 0.09858719069510698\n",
      "Epoch: 12, Batch: 300, Loss: 0.1057476425357163\n",
      "Epoch: 12, Batch: 400, Loss: 0.09252941428683698\n",
      "Epoch: 12, Batch: 500, Loss: 0.08614308641292155\n",
      "Epoch: 12, Batch: 600, Loss: 0.10552337991073728\n",
      "Epoch: 13, Batch: 100, Loss: 0.14731373341754078\n",
      "Epoch: 13, Batch: 200, Loss: 0.08561620610766113\n",
      "Epoch: 13, Batch: 300, Loss: 0.09274744533002377\n",
      "Epoch: 13, Batch: 400, Loss: 0.0901233443710953\n",
      "Epoch: 13, Batch: 500, Loss: 0.09138060563243926\n",
      "Epoch: 13, Batch: 600, Loss: 0.09549226234667003\n",
      "Epoch: 14, Batch: 100, Loss: 0.1269932899577543\n",
      "Epoch: 14, Batch: 200, Loss: 0.08862844556570053\n",
      "Epoch: 14, Batch: 300, Loss: 0.08823246015235782\n",
      "Epoch: 14, Batch: 400, Loss: 0.08450847958214582\n",
      "Epoch: 14, Batch: 500, Loss: 0.0878246362041682\n",
      "Epoch: 14, Batch: 600, Loss: 0.08950427700765431\n",
      "Epoch: 15, Batch: 100, Loss: 0.13252799990586936\n",
      "Epoch: 15, Batch: 200, Loss: 0.07955850253812968\n",
      "Epoch: 15, Batch: 300, Loss: 0.10582907745614648\n",
      "Epoch: 15, Batch: 400, Loss: 0.08428074855357409\n",
      "Epoch: 15, Batch: 500, Loss: 0.08634955195710063\n",
      "Epoch: 15, Batch: 600, Loss: 0.07601726121734828\n",
      "Epoch: 16, Batch: 100, Loss: 0.11894047473557294\n",
      "Epoch: 16, Batch: 200, Loss: 0.07393951319158078\n",
      "Epoch: 16, Batch: 300, Loss: 0.07525808520615102\n",
      "Epoch: 16, Batch: 400, Loss: 0.08644793000072241\n",
      "Epoch: 16, Batch: 500, Loss: 0.08878369411453604\n",
      "Epoch: 16, Batch: 600, Loss: 0.07437403928488492\n",
      "Epoch: 17, Batch: 100, Loss: 0.1287707969918847\n",
      "Epoch: 17, Batch: 200, Loss: 0.07510445316787809\n",
      "Epoch: 17, Batch: 300, Loss: 0.07638510687276721\n",
      "Epoch: 17, Batch: 400, Loss: 0.07130242129322141\n",
      "Epoch: 17, Batch: 500, Loss: 0.0817017417959869\n",
      "Epoch: 17, Batch: 600, Loss: 0.07014191467314959\n",
      "Epoch: 18, Batch: 100, Loss: 0.11448622780852019\n",
      "Epoch: 18, Batch: 200, Loss: 0.07056478691287339\n",
      "Epoch: 18, Batch: 300, Loss: 0.08039054063148797\n",
      "Epoch: 18, Batch: 400, Loss: 0.07233734638430178\n",
      "Epoch: 18, Batch: 500, Loss: 0.07914209228474647\n",
      "Epoch: 18, Batch: 600, Loss: 0.07159460394643247\n",
      "Epoch: 19, Batch: 100, Loss: 0.11747164738830179\n",
      "Epoch: 19, Batch: 200, Loss: 0.07936732270754873\n",
      "Epoch: 19, Batch: 300, Loss: 0.06556308886036277\n",
      "Epoch: 19, Batch: 400, Loss: 0.0750412374874577\n",
      "Epoch: 19, Batch: 500, Loss: 0.06735081845894456\n",
      "Epoch: 19, Batch: 600, Loss: 0.07552864924538881\n",
      "Epoch: 20, Batch: 100, Loss: 0.11005084432661533\n",
      "Epoch: 20, Batch: 200, Loss: 0.07433079403825105\n",
      "Epoch: 20, Batch: 300, Loss: 0.060520543083548546\n",
      "Epoch: 20, Batch: 400, Loss: 0.06631160874385386\n",
      "Epoch: 20, Batch: 500, Loss: 0.07125209642108529\n",
      "Epoch: 20, Batch: 600, Loss: 0.07944455063901841\n",
      "Epoch: 21, Batch: 100, Loss: 0.10854083066806197\n",
      "Epoch: 21, Batch: 200, Loss: 0.0629537222115323\n",
      "Epoch: 21, Batch: 300, Loss: 0.06739424415398389\n",
      "Epoch: 21, Batch: 400, Loss: 0.0616673948476091\n",
      "Epoch: 21, Batch: 500, Loss: 0.06903703852556646\n",
      "Epoch: 21, Batch: 600, Loss: 0.06803834809921681\n",
      "Epoch: 22, Batch: 100, Loss: 0.10152915325947105\n",
      "Epoch: 22, Batch: 200, Loss: 0.068941123271361\n",
      "Epoch: 22, Batch: 300, Loss: 0.06700533220544458\n",
      "Epoch: 22, Batch: 400, Loss: 0.0744769974425435\n",
      "Epoch: 22, Batch: 500, Loss: 0.06483806205913424\n",
      "Epoch: 22, Batch: 600, Loss: 0.0717782717384398\n",
      "Epoch: 23, Batch: 100, Loss: 0.11174521633889527\n",
      "Epoch: 23, Batch: 200, Loss: 0.07483428424224257\n",
      "Epoch: 23, Batch: 300, Loss: 0.06296790059655905\n",
      "Epoch: 23, Batch: 400, Loss: 0.07143476351164281\n",
      "Epoch: 23, Batch: 500, Loss: 0.06064728412311524\n",
      "Epoch: 23, Batch: 600, Loss: 0.068380370256491\n",
      "Epoch: 24, Batch: 100, Loss: 0.09722804493270815\n",
      "Epoch: 24, Batch: 200, Loss: 0.06710453097010032\n",
      "Epoch: 24, Batch: 300, Loss: 0.06436643031891436\n",
      "Epoch: 24, Batch: 400, Loss: 0.060045260619372126\n",
      "Epoch: 24, Batch: 500, Loss: 0.06855513460468501\n",
      "Epoch: 24, Batch: 600, Loss: 0.06601687023416161\n",
      "Epoch: 25, Batch: 100, Loss: 0.09008656351361424\n",
      "Epoch: 25, Batch: 200, Loss: 0.06725950470194221\n",
      "Epoch: 25, Batch: 300, Loss: 0.07275690672919154\n",
      "Epoch: 25, Batch: 400, Loss: 0.06136046502739191\n",
      "Epoch: 25, Batch: 500, Loss: 0.054434545398689804\n",
      "Epoch: 25, Batch: 600, Loss: 0.05867488816846162\n",
      "Epoch: 26, Batch: 100, Loss: 0.08387060914421454\n",
      "Epoch: 26, Batch: 200, Loss: 0.0604449253459461\n",
      "Epoch: 26, Batch: 300, Loss: 0.05452345826663077\n",
      "Epoch: 26, Batch: 400, Loss: 0.07169216909911484\n",
      "Epoch: 26, Batch: 500, Loss: 0.06166879217606038\n",
      "Epoch: 26, Batch: 600, Loss: 0.05938519159797579\n",
      "Epoch: 27, Batch: 100, Loss: 0.09399158926215023\n",
      "Epoch: 27, Batch: 200, Loss: 0.06363090184982866\n",
      "Epoch: 27, Batch: 300, Loss: 0.05819106867536902\n",
      "Epoch: 27, Batch: 400, Loss: 0.06011574741918593\n",
      "Epoch: 27, Batch: 500, Loss: 0.0501074844179675\n",
      "Epoch: 27, Batch: 600, Loss: 0.0598938798205927\n",
      "Epoch: 28, Batch: 100, Loss: 0.0921760446485132\n",
      "Epoch: 28, Batch: 200, Loss: 0.054510523220524194\n",
      "Epoch: 28, Batch: 300, Loss: 0.05975286398082971\n",
      "Epoch: 28, Batch: 400, Loss: 0.062456465028226375\n",
      "Epoch: 28, Batch: 500, Loss: 0.05238395345862955\n",
      "Epoch: 28, Batch: 600, Loss: 0.05990949157159776\n",
      "Epoch: 29, Batch: 100, Loss: 0.09126960000954569\n",
      "Epoch: 29, Batch: 200, Loss: 0.05051460821181536\n",
      "Epoch: 29, Batch: 300, Loss: 0.0640523531427607\n",
      "Epoch: 29, Batch: 400, Loss: 0.055980417714454236\n",
      "Epoch: 29, Batch: 500, Loss: 0.0600845657940954\n",
      "Epoch: 29, Batch: 600, Loss: 0.06174946203827858\n",
      "Epoch: 30, Batch: 100, Loss: 0.08477810703683644\n",
      "Epoch: 30, Batch: 200, Loss: 0.056799166870769115\n",
      "Epoch: 30, Batch: 300, Loss: 0.06233043902553618\n",
      "Epoch: 30, Batch: 400, Loss: 0.05046388777438551\n",
      "Epoch: 30, Batch: 500, Loss: 0.0526138787297532\n",
      "Epoch: 30, Batch: 600, Loss: 0.055881823806557804\n",
      "Epoch: 31, Batch: 100, Loss: 0.09836769375484437\n",
      "Epoch: 31, Batch: 200, Loss: 0.05353434929158538\n",
      "Epoch: 31, Batch: 300, Loss: 0.05515243971254677\n",
      "Epoch: 31, Batch: 400, Loss: 0.05140960769727826\n",
      "Epoch: 31, Batch: 500, Loss: 0.056187130091711876\n",
      "Epoch: 31, Batch: 600, Loss: 0.05135664428584277\n",
      "Epoch: 32, Batch: 100, Loss: 0.08474861843511462\n",
      "Epoch: 32, Batch: 200, Loss: 0.04739483515266329\n",
      "Epoch: 32, Batch: 300, Loss: 0.05331585286417976\n",
      "Epoch: 32, Batch: 400, Loss: 0.0548079008422792\n",
      "Epoch: 32, Batch: 500, Loss: 0.05624925798503682\n",
      "Epoch: 32, Batch: 600, Loss: 0.052067447802983224\n",
      "Epoch: 33, Batch: 100, Loss: 0.07711599978851154\n",
      "Epoch: 33, Batch: 200, Loss: 0.05219506243709475\n",
      "Epoch: 33, Batch: 300, Loss: 0.054734496579039844\n",
      "Epoch: 33, Batch: 400, Loss: 0.05183587467065081\n",
      "Epoch: 33, Batch: 500, Loss: 0.044852313650771976\n",
      "Epoch: 33, Batch: 600, Loss: 0.05580574942985549\n",
      "Epoch: 34, Batch: 100, Loss: 0.08316418763657567\n",
      "Epoch: 34, Batch: 200, Loss: 0.05045607061125338\n",
      "Epoch: 34, Batch: 300, Loss: 0.05024719782872125\n",
      "Epoch: 34, Batch: 400, Loss: 0.054470181341748684\n",
      "Epoch: 34, Batch: 500, Loss: 0.050935893598943946\n",
      "Epoch: 34, Batch: 600, Loss: 0.05080243473639712\n",
      "Epoch: 35, Batch: 100, Loss: 0.0839301068277564\n",
      "Epoch: 35, Batch: 200, Loss: 0.046291305040940645\n",
      "Epoch: 35, Batch: 300, Loss: 0.04427300645271316\n",
      "Epoch: 35, Batch: 400, Loss: 0.05442672536708414\n",
      "Epoch: 35, Batch: 500, Loss: 0.04942698755767196\n",
      "Epoch: 35, Batch: 600, Loss: 0.05245304426411167\n",
      "Epoch: 36, Batch: 100, Loss: 0.08415558118838817\n",
      "Epoch: 36, Batch: 200, Loss: 0.042227667679544535\n",
      "Epoch: 36, Batch: 300, Loss: 0.0471721984713804\n",
      "Epoch: 36, Batch: 400, Loss: 0.049530187917407605\n",
      "Epoch: 36, Batch: 500, Loss: 0.0443323708511889\n",
      "Epoch: 36, Batch: 600, Loss: 0.048509547335561364\n",
      "Epoch: 37, Batch: 100, Loss: 0.08117909057764336\n",
      "Epoch: 37, Batch: 200, Loss: 0.04062408057972789\n",
      "Epoch: 37, Batch: 300, Loss: 0.052379986778832974\n",
      "Epoch: 37, Batch: 400, Loss: 0.05599536264780909\n",
      "Epoch: 37, Batch: 500, Loss: 0.04525324638001621\n",
      "Epoch: 37, Batch: 600, Loss: 0.04169057600083761\n",
      "Epoch: 38, Batch: 100, Loss: 0.08011585547123104\n",
      "Epoch: 38, Batch: 200, Loss: 0.04553819770924747\n",
      "Epoch: 38, Batch: 300, Loss: 0.045290151766967025\n",
      "Epoch: 38, Batch: 400, Loss: 0.04284866132773459\n",
      "Epoch: 38, Batch: 500, Loss: 0.057336096591316166\n",
      "Epoch: 38, Batch: 600, Loss: 0.05677296823821962\n",
      "Epoch: 39, Batch: 100, Loss: 0.0740856477851048\n",
      "Epoch: 39, Batch: 200, Loss: 0.04040853513404727\n",
      "Epoch: 39, Batch: 300, Loss: 0.04734182410873473\n",
      "Epoch: 39, Batch: 400, Loss: 0.04604773507453501\n",
      "Epoch: 39, Batch: 500, Loss: 0.04515234312741086\n",
      "Epoch: 39, Batch: 600, Loss: 0.05445910854963586\n",
      "Epoch: 40, Batch: 100, Loss: 0.07666129744146019\n",
      "Epoch: 40, Batch: 200, Loss: 0.04580836456269026\n",
      "Epoch: 40, Batch: 300, Loss: 0.050846597326453774\n",
      "Epoch: 40, Batch: 400, Loss: 0.043147337541449816\n",
      "Epoch: 40, Batch: 500, Loss: 0.043271897458471355\n",
      "Epoch: 40, Batch: 600, Loss: 0.05196076847612858\n",
      "Epoch: 41, Batch: 100, Loss: 0.0708509742305614\n",
      "Epoch: 41, Batch: 200, Loss: 0.041389169404283166\n",
      "Epoch: 41, Batch: 300, Loss: 0.04163057953352109\n",
      "Epoch: 41, Batch: 400, Loss: 0.04195351320086047\n",
      "Epoch: 41, Batch: 500, Loss: 0.05304382249945774\n",
      "Epoch: 41, Batch: 600, Loss: 0.046294077867642044\n",
      "Epoch: 42, Batch: 100, Loss: 0.0653507654252462\n",
      "Epoch: 42, Batch: 200, Loss: 0.04413673480274156\n",
      "Epoch: 42, Batch: 300, Loss: 0.0423271201713942\n",
      "Epoch: 42, Batch: 400, Loss: 0.051825098381377756\n",
      "Epoch: 42, Batch: 500, Loss: 0.04224957117345184\n",
      "Epoch: 42, Batch: 600, Loss: 0.03969740064814687\n",
      "Epoch: 43, Batch: 100, Loss: 0.06404939766740426\n",
      "Epoch: 43, Batch: 200, Loss: 0.04093950246926397\n",
      "Epoch: 43, Batch: 300, Loss: 0.05096693739527836\n",
      "Epoch: 43, Batch: 400, Loss: 0.04247851420426741\n",
      "Epoch: 43, Batch: 500, Loss: 0.04651987448101863\n",
      "Epoch: 43, Batch: 600, Loss: 0.044354383335448805\n",
      "Epoch: 44, Batch: 100, Loss: 0.06357627629069612\n",
      "Epoch: 44, Batch: 200, Loss: 0.041953139847028066\n",
      "Epoch: 44, Batch: 300, Loss: 0.04764459049096331\n",
      "Epoch: 44, Batch: 400, Loss: 0.04295436408603564\n",
      "Epoch: 44, Batch: 500, Loss: 0.03723004590254277\n",
      "Epoch: 44, Batch: 600, Loss: 0.03888239499181509\n",
      "Epoch: 45, Batch: 100, Loss: 0.077395913337823\n",
      "Epoch: 45, Batch: 200, Loss: 0.03935075805755332\n",
      "Epoch: 45, Batch: 300, Loss: 0.04070810269447975\n",
      "Epoch: 45, Batch: 400, Loss: 0.03975788103882223\n",
      "Epoch: 45, Batch: 500, Loss: 0.042059333568904546\n",
      "Epoch: 45, Batch: 600, Loss: 0.04389103520195931\n",
      "Epoch: 46, Batch: 100, Loss: 0.06862342310952954\n",
      "Epoch: 46, Batch: 200, Loss: 0.0468659496481996\n",
      "Epoch: 46, Batch: 300, Loss: 0.03860884019872174\n",
      "Epoch: 46, Batch: 400, Loss: 0.04407804646063596\n",
      "Epoch: 46, Batch: 500, Loss: 0.03879964734660461\n",
      "Epoch: 46, Batch: 600, Loss: 0.039715457381680606\n",
      "Epoch: 47, Batch: 100, Loss: 0.062381452085683124\n",
      "Epoch: 47, Batch: 200, Loss: 0.04482505845604465\n",
      "Epoch: 47, Batch: 300, Loss: 0.032161901434883476\n",
      "Epoch: 47, Batch: 400, Loss: 0.04333051896654069\n",
      "Epoch: 47, Batch: 500, Loss: 0.042048049313016235\n",
      "Epoch: 47, Batch: 600, Loss: 0.04257260871352628\n",
      "Epoch: 48, Batch: 100, Loss: 0.06405014684569324\n",
      "Epoch: 48, Batch: 200, Loss: 0.038454400040209294\n",
      "Epoch: 48, Batch: 300, Loss: 0.04633824348682538\n",
      "Epoch: 48, Batch: 400, Loss: 0.03904829327715561\n",
      "Epoch: 48, Batch: 500, Loss: 0.03927078225649893\n",
      "Epoch: 48, Batch: 600, Loss: 0.037462134289089594\n",
      "Epoch: 49, Batch: 100, Loss: 0.054709260339150204\n",
      "Epoch: 49, Batch: 200, Loss: 0.03487051117699593\n",
      "Epoch: 49, Batch: 300, Loss: 0.037706384519115094\n",
      "Epoch: 49, Batch: 400, Loss: 0.035882647596299645\n",
      "Epoch: 49, Batch: 500, Loss: 0.04264809131273069\n",
      "Epoch: 49, Batch: 600, Loss: 0.04252535142935812\n",
      "Epoch: 50, Batch: 100, Loss: 0.059835002955514936\n",
      "Epoch: 50, Batch: 200, Loss: 0.0420231101103127\n",
      "Epoch: 50, Batch: 300, Loss: 0.04202395680127666\n",
      "Epoch: 50, Batch: 400, Loss: 0.03699065668391995\n",
      "Epoch: 50, Batch: 500, Loss: 0.04092602510820143\n",
      "Epoch: 50, Batch: 600, Loss: 0.03985034148208797\n",
      "Epoch: 51, Batch: 100, Loss: 0.056473266611574216\n",
      "Epoch: 51, Batch: 200, Loss: 0.04362610574113205\n",
      "Epoch: 51, Batch: 300, Loss: 0.04156278535258025\n",
      "Epoch: 51, Batch: 400, Loss: 0.03834074234124273\n",
      "Epoch: 51, Batch: 500, Loss: 0.037149071380263195\n",
      "Epoch: 51, Batch: 600, Loss: 0.04108047103742138\n",
      "Epoch: 52, Batch: 100, Loss: 0.06308658503810875\n",
      "Epoch: 52, Batch: 200, Loss: 0.035453152917325495\n",
      "Epoch: 52, Batch: 300, Loss: 0.038101896638981995\n",
      "Epoch: 52, Batch: 400, Loss: 0.03677638007502537\n",
      "Epoch: 52, Batch: 500, Loss: 0.03994241582287941\n",
      "Epoch: 52, Batch: 600, Loss: 0.04138462549075484\n",
      "Epoch: 53, Batch: 100, Loss: 0.05974139013618696\n",
      "Epoch: 53, Batch: 200, Loss: 0.03819484894163907\n",
      "Epoch: 53, Batch: 300, Loss: 0.035779609028249976\n",
      "Epoch: 53, Batch: 400, Loss: 0.03040356148034334\n",
      "Epoch: 53, Batch: 500, Loss: 0.03545183123089373\n",
      "Epoch: 53, Batch: 600, Loss: 0.03974184749647975\n",
      "Epoch: 54, Batch: 100, Loss: 0.06211279322742484\n",
      "Epoch: 54, Batch: 200, Loss: 0.03270852442306932\n",
      "Epoch: 54, Batch: 300, Loss: 0.0367098409938626\n",
      "Epoch: 54, Batch: 400, Loss: 0.0351661820942536\n",
      "Epoch: 54, Batch: 500, Loss: 0.04086449003079906\n",
      "Epoch: 54, Batch: 600, Loss: 0.03845724198967218\n",
      "Epoch: 55, Batch: 100, Loss: 0.05761079831281677\n",
      "Epoch: 55, Batch: 200, Loss: 0.03468498450703919\n",
      "Epoch: 55, Batch: 300, Loss: 0.032034883230226116\n",
      "Epoch: 55, Batch: 400, Loss: 0.03370452692732215\n",
      "Epoch: 55, Batch: 500, Loss: 0.04076318179839291\n",
      "Epoch: 55, Batch: 600, Loss: 0.037324894389603284\n",
      "Epoch: 56, Batch: 100, Loss: 0.06573857350507752\n",
      "Epoch: 56, Batch: 200, Loss: 0.036462301303399725\n",
      "Epoch: 56, Batch: 300, Loss: 0.033935167477466166\n",
      "Epoch: 56, Batch: 400, Loss: 0.03257377303671092\n",
      "Epoch: 56, Batch: 500, Loss: 0.03180949023924768\n",
      "Epoch: 56, Batch: 600, Loss: 0.04290486727142707\n",
      "Epoch: 57, Batch: 100, Loss: 0.05512547702528536\n",
      "Epoch: 57, Batch: 200, Loss: 0.0350258943461813\n",
      "Epoch: 57, Batch: 300, Loss: 0.03680348992929794\n",
      "Epoch: 57, Batch: 400, Loss: 0.0336555153678637\n",
      "Epoch: 57, Batch: 500, Loss: 0.036016320104245096\n",
      "Epoch: 57, Batch: 600, Loss: 0.03863326964434236\n",
      "Epoch: 58, Batch: 100, Loss: 0.05576706607011147\n",
      "Epoch: 58, Batch: 200, Loss: 0.03535316637833603\n",
      "Epoch: 58, Batch: 300, Loss: 0.033585572851588946\n",
      "Epoch: 58, Batch: 400, Loss: 0.03398948962392751\n",
      "Epoch: 58, Batch: 500, Loss: 0.03975026444066316\n",
      "Epoch: 58, Batch: 600, Loss: 0.033511234825709835\n",
      "Epoch: 59, Batch: 100, Loss: 0.053820144938654266\n",
      "Epoch: 59, Batch: 200, Loss: 0.03465132820187136\n",
      "Epoch: 59, Batch: 300, Loss: 0.038265031147748235\n",
      "Epoch: 59, Batch: 400, Loss: 0.033774015412200244\n",
      "Epoch: 59, Batch: 500, Loss: 0.028567636413499714\n",
      "Epoch: 59, Batch: 600, Loss: 0.03505716251558624\n",
      "Epoch: 60, Batch: 100, Loss: 0.04786145809222944\n",
      "Epoch: 60, Batch: 200, Loss: 0.03326382854254916\n",
      "Epoch: 60, Batch: 300, Loss: 0.03888955993112177\n",
      "Epoch: 60, Batch: 400, Loss: 0.03400314752245322\n",
      "Epoch: 60, Batch: 500, Loss: 0.039261176616419105\n",
      "Epoch: 60, Batch: 600, Loss: 0.030762216002913192\n",
      "Epoch: 61, Batch: 100, Loss: 0.05988604907412082\n",
      "Epoch: 61, Batch: 200, Loss: 0.038544419910758736\n",
      "Epoch: 61, Batch: 300, Loss: 0.029099215894239024\n",
      "Epoch: 61, Batch: 400, Loss: 0.028967004792648368\n",
      "Epoch: 61, Batch: 500, Loss: 0.04298101242166012\n",
      "Epoch: 61, Batch: 600, Loss: 0.035920100740622726\n",
      "Epoch: 62, Batch: 100, Loss: 0.04597889391006902\n",
      "Epoch: 62, Batch: 200, Loss: 0.0325718562444672\n",
      "Epoch: 62, Batch: 300, Loss: 0.03571284461446339\n",
      "Epoch: 62, Batch: 400, Loss: 0.030087804078357296\n",
      "Epoch: 62, Batch: 500, Loss: 0.033157285719644276\n",
      "Epoch: 62, Batch: 600, Loss: 0.02828546475735493\n",
      "Epoch: 63, Batch: 100, Loss: 0.06037955810083076\n",
      "Epoch: 63, Batch: 200, Loss: 0.03600798509316519\n",
      "Epoch: 63, Batch: 300, Loss: 0.030057212772080674\n",
      "Epoch: 63, Batch: 400, Loss: 0.031456878090975804\n",
      "Epoch: 63, Batch: 500, Loss: 0.027160016296838875\n",
      "Epoch: 63, Batch: 600, Loss: 0.03693885216256604\n",
      "Epoch: 64, Batch: 100, Loss: 0.05429009588318877\n",
      "Epoch: 64, Batch: 200, Loss: 0.030892866787908133\n",
      "Epoch: 64, Batch: 300, Loss: 0.033605700933840126\n",
      "Epoch: 64, Batch: 400, Loss: 0.03080662459367886\n",
      "Epoch: 64, Batch: 500, Loss: 0.030507788718678056\n",
      "Epoch: 64, Batch: 600, Loss: 0.03704705382697284\n",
      "Epoch: 65, Batch: 100, Loss: 0.047906537516973914\n",
      "Epoch: 65, Batch: 200, Loss: 0.03078192845394369\n",
      "Epoch: 65, Batch: 300, Loss: 0.02813740586163476\n",
      "Epoch: 65, Batch: 400, Loss: 0.028582408317015508\n",
      "Epoch: 65, Batch: 500, Loss: 0.03723396477464121\n",
      "Epoch: 65, Batch: 600, Loss: 0.035137919707922266\n",
      "Epoch: 66, Batch: 100, Loss: 0.050317395499441774\n",
      "Epoch: 66, Batch: 200, Loss: 0.0359748761577066\n",
      "Epoch: 66, Batch: 300, Loss: 0.034345182474935426\n",
      "Epoch: 66, Batch: 400, Loss: 0.03077537951176055\n",
      "Epoch: 66, Batch: 500, Loss: 0.030781570051331072\n",
      "Epoch: 66, Batch: 600, Loss: 0.037855972335673865\n",
      "Epoch: 67, Batch: 100, Loss: 0.046777378059341575\n",
      "Epoch: 67, Batch: 200, Loss: 0.03352587454020977\n",
      "Epoch: 67, Batch: 300, Loss: 0.027141159337479622\n",
      "Epoch: 67, Batch: 400, Loss: 0.028290025767637415\n",
      "Epoch: 67, Batch: 500, Loss: 0.023309232104802503\n",
      "Epoch: 67, Batch: 600, Loss: 0.0352735805301927\n",
      "Epoch: 68, Batch: 100, Loss: 0.051829141398193314\n",
      "Epoch: 68, Batch: 200, Loss: 0.026687323397491126\n",
      "Epoch: 68, Batch: 300, Loss: 0.024383462101686747\n",
      "Epoch: 68, Batch: 400, Loss: 0.031610440420918165\n",
      "Epoch: 68, Batch: 500, Loss: 0.028215719148283823\n",
      "Epoch: 68, Batch: 600, Loss: 0.03062993404804729\n",
      "Epoch: 69, Batch: 100, Loss: 0.045555762735311874\n",
      "Epoch: 69, Batch: 200, Loss: 0.032081973899621516\n",
      "Epoch: 69, Batch: 300, Loss: 0.03547875859658234\n",
      "Epoch: 69, Batch: 400, Loss: 0.027952404355164617\n",
      "Epoch: 69, Batch: 500, Loss: 0.03425508928135969\n",
      "Epoch: 69, Batch: 600, Loss: 0.033199503832729536\n",
      "Epoch: 70, Batch: 100, Loss: 0.04467105636664201\n",
      "Epoch: 70, Batch: 200, Loss: 0.027744802506058475\n",
      "Epoch: 70, Batch: 300, Loss: 0.03169657244114205\n",
      "Epoch: 70, Batch: 400, Loss: 0.03183599735144526\n",
      "Epoch: 70, Batch: 500, Loss: 0.02837389988824725\n",
      "Epoch: 70, Batch: 600, Loss: 0.027210596986114978\n",
      "Epoch: 71, Batch: 100, Loss: 0.05629556581552606\n",
      "Epoch: 71, Batch: 200, Loss: 0.031725286174914796\n",
      "Epoch: 71, Batch: 300, Loss: 0.026424270534771494\n",
      "Epoch: 71, Batch: 400, Loss: 0.032651478168554605\n",
      "Epoch: 71, Batch: 500, Loss: 0.024679939358029514\n",
      "Epoch: 71, Batch: 600, Loss: 0.028066475946689026\n",
      "Epoch: 72, Batch: 100, Loss: 0.04058075315493625\n",
      "Epoch: 72, Batch: 200, Loss: 0.026982420830754562\n",
      "Epoch: 72, Batch: 300, Loss: 0.03626429507276043\n",
      "Epoch: 72, Batch: 400, Loss: 0.028201083607855254\n",
      "Epoch: 72, Batch: 500, Loss: 0.033210238183382895\n",
      "Epoch: 72, Batch: 600, Loss: 0.030325007679639384\n",
      "Epoch: 73, Batch: 100, Loss: 0.0470688551897183\n",
      "Epoch: 73, Batch: 200, Loss: 0.030482706802431495\n",
      "Epoch: 73, Batch: 300, Loss: 0.02273344733606791\n",
      "Epoch: 73, Batch: 400, Loss: 0.0269631262117764\n",
      "Epoch: 73, Batch: 500, Loss: 0.035424184491857885\n",
      "Epoch: 73, Batch: 600, Loss: 0.028295971766347065\n",
      "Epoch: 74, Batch: 100, Loss: 0.045886416294961235\n",
      "Epoch: 74, Batch: 200, Loss: 0.030374287244048902\n",
      "Epoch: 74, Batch: 300, Loss: 0.030540641692932694\n",
      "Epoch: 74, Batch: 400, Loss: 0.027173802009783685\n",
      "Epoch: 74, Batch: 500, Loss: 0.03282552857650444\n",
      "Epoch: 74, Batch: 600, Loss: 0.025824252066086045\n",
      "Epoch: 75, Batch: 100, Loss: 0.0464267233456485\n",
      "Epoch: 75, Batch: 200, Loss: 0.028909130315296353\n",
      "Epoch: 75, Batch: 300, Loss: 0.030655918702250345\n",
      "Epoch: 75, Batch: 400, Loss: 0.028969153768848628\n",
      "Epoch: 75, Batch: 500, Loss: 0.02546195518458262\n",
      "Epoch: 75, Batch: 600, Loss: 0.02820420926786028\n",
      "Epoch: 76, Batch: 100, Loss: 0.048575071871700855\n",
      "Epoch: 76, Batch: 200, Loss: 0.02527292010607198\n",
      "Epoch: 76, Batch: 300, Loss: 0.031770277132745835\n",
      "Epoch: 76, Batch: 400, Loss: 0.029527584168245084\n",
      "Epoch: 76, Batch: 500, Loss: 0.027258751305053012\n",
      "Epoch: 76, Batch: 600, Loss: 0.028917205182369798\n",
      "Epoch: 77, Batch: 100, Loss: 0.0537155843549408\n",
      "Epoch: 77, Batch: 200, Loss: 0.026279087201110087\n",
      "Epoch: 77, Batch: 300, Loss: 0.02563131182687357\n",
      "Epoch: 77, Batch: 400, Loss: 0.028619710562052206\n",
      "Epoch: 77, Batch: 500, Loss: 0.02939158274442889\n",
      "Epoch: 77, Batch: 600, Loss: 0.028912665222305803\n",
      "Epoch: 78, Batch: 100, Loss: 0.04353191855945624\n",
      "Epoch: 78, Batch: 200, Loss: 0.029253815204720014\n",
      "Epoch: 78, Batch: 300, Loss: 0.025066945871221834\n",
      "Epoch: 78, Batch: 400, Loss: 0.02987390195718035\n",
      "Epoch: 78, Batch: 500, Loss: 0.02670727312681265\n",
      "Epoch: 78, Batch: 600, Loss: 0.029813876091502607\n",
      "Epoch: 79, Batch: 100, Loss: 0.0428570021071937\n",
      "Epoch: 79, Batch: 200, Loss: 0.024118389859213493\n",
      "Epoch: 79, Batch: 300, Loss: 0.030089866553316823\n",
      "Epoch: 79, Batch: 400, Loss: 0.030132648603757844\n",
      "Epoch: 79, Batch: 500, Loss: 0.02680569128948264\n",
      "Epoch: 79, Batch: 600, Loss: 0.02851056354586035\n",
      "Epoch: 80, Batch: 100, Loss: 0.04181621388182975\n",
      "Epoch: 80, Batch: 200, Loss: 0.028847531562205403\n",
      "Epoch: 80, Batch: 300, Loss: 0.025043290418107062\n",
      "Epoch: 80, Batch: 400, Loss: 0.026090714602032675\n",
      "Epoch: 80, Batch: 500, Loss: 0.028906218833290042\n",
      "Epoch: 80, Batch: 600, Loss: 0.024730405816808344\n",
      "Epoch: 81, Batch: 100, Loss: 0.0512846332625486\n",
      "Epoch: 81, Batch: 200, Loss: 0.022714285561814904\n",
      "Epoch: 81, Batch: 300, Loss: 0.02915527447592467\n",
      "Epoch: 81, Batch: 400, Loss: 0.0300940406776499\n",
      "Epoch: 81, Batch: 500, Loss: 0.02506027928320691\n",
      "Epoch: 81, Batch: 600, Loss: 0.027432430592598395\n",
      "Epoch: 82, Batch: 100, Loss: 0.034636554741591684\n",
      "Epoch: 82, Batch: 200, Loss: 0.027342749976087363\n",
      "Epoch: 82, Batch: 300, Loss: 0.02265826811781153\n",
      "Epoch: 82, Batch: 400, Loss: 0.02874341584101785\n",
      "Epoch: 82, Batch: 500, Loss: 0.02414929972961545\n",
      "Epoch: 82, Batch: 600, Loss: 0.025605182440485805\n",
      "Epoch: 83, Batch: 100, Loss: 0.03523692535411101\n",
      "Epoch: 83, Batch: 200, Loss: 0.02846312012145063\n",
      "Epoch: 83, Batch: 300, Loss: 0.029944764806423337\n",
      "Epoch: 83, Batch: 400, Loss: 0.02954608116939198\n",
      "Epoch: 83, Batch: 500, Loss: 0.024233057224191727\n",
      "Epoch: 83, Batch: 600, Loss: 0.025292456742899958\n",
      "Epoch: 84, Batch: 100, Loss: 0.03890529987460468\n",
      "Epoch: 84, Batch: 200, Loss: 0.021409561616601423\n",
      "Epoch: 84, Batch: 300, Loss: 0.03075671999133192\n",
      "Epoch: 84, Batch: 400, Loss: 0.024946470779832454\n",
      "Epoch: 84, Batch: 500, Loss: 0.02488538693753071\n",
      "Epoch: 84, Batch: 600, Loss: 0.024544480026233943\n",
      "Epoch: 85, Batch: 100, Loss: 0.04173022528761067\n",
      "Epoch: 85, Batch: 200, Loss: 0.025693069456610828\n",
      "Epoch: 85, Batch: 300, Loss: 0.025057694575516508\n",
      "Epoch: 85, Batch: 400, Loss: 0.027657360082957893\n",
      "Epoch: 85, Batch: 500, Loss: 0.02637158614350483\n",
      "Epoch: 85, Batch: 600, Loss: 0.02510496754432097\n",
      "Epoch: 86, Batch: 100, Loss: 0.04184114178293385\n",
      "Epoch: 86, Batch: 200, Loss: 0.021297251929645426\n",
      "Epoch: 86, Batch: 300, Loss: 0.023747387559269556\n",
      "Epoch: 86, Batch: 400, Loss: 0.022901672846637668\n",
      "Epoch: 86, Batch: 500, Loss: 0.02668475172657054\n",
      "Epoch: 86, Batch: 600, Loss: 0.025981488401303068\n",
      "Epoch: 87, Batch: 100, Loss: 0.04479724796314258\n",
      "Epoch: 87, Batch: 200, Loss: 0.02141863137134351\n",
      "Epoch: 87, Batch: 300, Loss: 0.026791717516025527\n",
      "Epoch: 87, Batch: 400, Loss: 0.02608196651475737\n",
      "Epoch: 87, Batch: 500, Loss: 0.023630093996180223\n",
      "Epoch: 87, Batch: 600, Loss: 0.022517064155545087\n",
      "Epoch: 88, Batch: 100, Loss: 0.03954224425542634\n",
      "Epoch: 88, Batch: 200, Loss: 0.0234920831839554\n",
      "Epoch: 88, Batch: 300, Loss: 0.023110001582535913\n",
      "Epoch: 88, Batch: 400, Loss: 0.025748501180205493\n",
      "Epoch: 88, Batch: 500, Loss: 0.02498610472888686\n",
      "Epoch: 88, Batch: 600, Loss: 0.031410115452017634\n",
      "Epoch: 89, Batch: 100, Loss: 0.040033956352854144\n",
      "Epoch: 89, Batch: 200, Loss: 0.023347794211586007\n",
      "Epoch: 89, Batch: 300, Loss: 0.020410688279662283\n",
      "Epoch: 89, Batch: 400, Loss: 0.02442734420648776\n",
      "Epoch: 89, Batch: 500, Loss: 0.021117147977929563\n",
      "Epoch: 89, Batch: 600, Loss: 0.025775987803936005\n",
      "Epoch: 90, Batch: 100, Loss: 0.03713340230402537\n",
      "Epoch: 90, Batch: 200, Loss: 0.024966263837413863\n",
      "Epoch: 90, Batch: 300, Loss: 0.027524404094438067\n",
      "Epoch: 90, Batch: 400, Loss: 0.025141571109415964\n",
      "Epoch: 90, Batch: 500, Loss: 0.022215852990048007\n",
      "Epoch: 90, Batch: 600, Loss: 0.026971064938697963\n",
      "Epoch: 91, Batch: 100, Loss: 0.03523097345969291\n",
      "Epoch: 91, Batch: 200, Loss: 0.022977390416199343\n",
      "Epoch: 91, Batch: 300, Loss: 0.019996622105827554\n",
      "Epoch: 91, Batch: 400, Loss: 0.026235566787363496\n",
      "Epoch: 91, Batch: 500, Loss: 0.022758659277460538\n",
      "Epoch: 91, Batch: 600, Loss: 0.027076924964785577\n",
      "Epoch: 92, Batch: 100, Loss: 0.03795495403930545\n",
      "Epoch: 92, Batch: 200, Loss: 0.023530749377096073\n",
      "Epoch: 92, Batch: 300, Loss: 0.02128386249853065\n",
      "Epoch: 92, Batch: 400, Loss: 0.02777351727185305\n",
      "Epoch: 92, Batch: 500, Loss: 0.022740489967982284\n",
      "Epoch: 92, Batch: 600, Loss: 0.020733255295199343\n",
      "Epoch: 93, Batch: 100, Loss: 0.03948143492976669\n",
      "Epoch: 93, Batch: 200, Loss: 0.024258998642035293\n",
      "Epoch: 93, Batch: 300, Loss: 0.019761989772086964\n",
      "Epoch: 93, Batch: 400, Loss: 0.025403049810847733\n",
      "Epoch: 93, Batch: 500, Loss: 0.024769368040724656\n",
      "Epoch: 93, Batch: 600, Loss: 0.025503680844558403\n",
      "Epoch: 94, Batch: 100, Loss: 0.040654039938817735\n",
      "Epoch: 94, Batch: 200, Loss: 0.02253880382690113\n",
      "Epoch: 94, Batch: 300, Loss: 0.0245499975560233\n",
      "Epoch: 94, Batch: 400, Loss: 0.026049309550726322\n",
      "Epoch: 94, Batch: 500, Loss: 0.02654493726207875\n",
      "Epoch: 94, Batch: 600, Loss: 0.017427556451293638\n",
      "Epoch: 95, Batch: 100, Loss: 0.035940378853701986\n",
      "Epoch: 95, Batch: 200, Loss: 0.025417523408541455\n",
      "Epoch: 95, Batch: 300, Loss: 0.021573495122720488\n",
      "Epoch: 95, Batch: 400, Loss: 0.021480320519767702\n",
      "Epoch: 95, Batch: 500, Loss: 0.02468203527329024\n",
      "Epoch: 95, Batch: 600, Loss: 0.024684366097208112\n",
      "Epoch: 96, Batch: 100, Loss: 0.03718046786030754\n",
      "Epoch: 96, Batch: 200, Loss: 0.023558807938825338\n",
      "Epoch: 96, Batch: 300, Loss: 0.023985397745273074\n",
      "Epoch: 96, Batch: 400, Loss: 0.019591477809735806\n",
      "Epoch: 96, Batch: 500, Loss: 0.020993047324591316\n",
      "Epoch: 96, Batch: 600, Loss: 0.023155079215648584\n",
      "Epoch: 97, Batch: 100, Loss: 0.039599607736454344\n",
      "Epoch: 97, Batch: 200, Loss: 0.022611459852778352\n",
      "Epoch: 97, Batch: 300, Loss: 0.019548174651281443\n",
      "Epoch: 97, Batch: 400, Loss: 0.020340085611096584\n",
      "Epoch: 97, Batch: 500, Loss: 0.02342711089993827\n",
      "Epoch: 97, Batch: 600, Loss: 0.030029419286875053\n",
      "Epoch: 98, Batch: 100, Loss: 0.032995162931620144\n",
      "Epoch: 98, Batch: 200, Loss: 0.018323385820258407\n",
      "Epoch: 98, Batch: 300, Loss: 0.02177378434862476\n",
      "Epoch: 98, Batch: 400, Loss: 0.023037689259217585\n",
      "Epoch: 98, Batch: 500, Loss: 0.026201042119064367\n",
      "Epoch: 98, Batch: 600, Loss: 0.020338148087612352\n",
      "Epoch: 99, Batch: 100, Loss: 0.03843110805682955\n",
      "Epoch: 99, Batch: 200, Loss: 0.01986935780296335\n",
      "Epoch: 99, Batch: 300, Loss: 0.022955346570815893\n",
      "Epoch: 99, Batch: 400, Loss: 0.021459383779001653\n",
      "Epoch: 99, Batch: 500, Loss: 0.023673064477625304\n",
      "Epoch: 99, Batch: 600, Loss: 0.016904584787553176\n",
      "Epoch: 100, Batch: 100, Loss: 0.031449532242259014\n",
      "Epoch: 100, Batch: 200, Loss: 0.020330192608525977\n",
      "Epoch: 100, Batch: 300, Loss: 0.022865957907488337\n",
      "Epoch: 100, Batch: 400, Loss: 0.021828141077421606\n",
      "Epoch: 100, Batch: 500, Loss: 0.019973352617817\n",
      "Epoch: 100, Batch: 600, Loss: 0.020626391251571476\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "running_loss = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  for i, data in enumerate(train_loader, 0):\n",
    "    inputs, labels = data\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    outputs = model(inputs.float())\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    running_loss += loss.item()\n",
    "\n",
    "    if i % 100 == 99:\n",
    "      print(f'Epoch: {epoch + 1}, Batch: {i + 1}, Loss: {running_loss / 100}')\n",
    "      running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "884adcf3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T06:33:39.731565Z",
     "iopub.status.busy": "2026-01-06T06:33:39.731215Z",
     "iopub.status.idle": "2026-01-06T06:34:00.024469Z",
     "shell.execute_reply": "2026-01-06T06:34:00.023168Z"
    },
    "papermill": {
     "duration": 20.327771,
     "end_time": "2026-01-06T06:34:00.026259",
     "exception": false,
     "start_time": "2026-01-06T06:33:39.698488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved!\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:      # use 'data' directly if no labels\n",
    "        data = data.to(device)    # move to GPU/CPU\n",
    "\n",
    "        outputs = model(data)     # forward pass\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        predictions.extend(predicted.cpu().tolist())  # fixed typo\n",
    "\n",
    "# Prepare submission\n",
    "submission = pd.DataFrame({\n",
    "    'ImageId': range(1, len(predictions) + 1),\n",
    "    'Label': predictions\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"Submission saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f87ba7f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T06:34:00.088841Z",
     "iopub.status.busy": "2026-01-06T06:34:00.087974Z",
     "iopub.status.idle": "2026-01-06T06:34:00.095040Z",
     "shell.execute_reply": "2026-01-06T06:34:00.094071Z"
    },
    "papermill": {
     "duration": 0.040558,
     "end_time": "2026-01-06T06:34:00.096416",
     "exception": false,
     "start_time": "2026-01-06T06:34:00.055858",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zipped!\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile('submission.zip', 'w') as z:\n",
    "    z.write('submission.csv')\n",
    "\n",
    "print(\"Zipped!\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "tpuV5e8",
   "dataSources": [
    {
     "databundleVersionId": 861823,
     "sourceId": 3004,
     "sourceType": "competition"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6624.624627,
   "end_time": "2026-01-06T06:34:03.131487",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-06T04:43:38.506860",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
